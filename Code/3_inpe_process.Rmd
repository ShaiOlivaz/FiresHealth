---
title: "INPE Data Processing"
author: "Shai Vaz"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
# Data Wrangling
library(dplyr)
library(tidyr)
library(stringr)
library(stringi)
library(readr)
library(lubridate)
library(fuzzyjoin)

# Fast Data
library(arrow)
library(duckdb)
library(dbplyr)
library(duckspatial)

# Geographic
library(sf)
library(duckspatial)

# Personal functions
source("./Functions/bulk_rds.R")
```

# Importing data as Arrow dataset

We import using the arrow library, and save as parquet files for fast retrieval.

## All Satellites

```{r}
dataset_csv_path = "../Inputs/fires/todos_sats/csv/"
dataset_parquet_path = "../Inputs/fires/todos_sats/parquet"

# Import csv
fires_all_sats = open_csv_dataset(
  dataset_csv_path,
  col_types = schema(
    numero_dias_sem_chuva = double(),
    precipitacao = double(),
    risco_fogo = double(),
    id_area_industrial = double(),
    frp = double()
  ) 
)

# Create Year and Month Columns
fires_all_sats <- fires_all_sats |> 
  mutate(
    year = year(data_pas),
    month = month(data_pas)
  )

# Export as Parquet
write_dataset(
  fires_all_sats,
  path = dataset_parquet_path,
  format = "parquet",
  partitioning = c("year")
)
```


## Reference Satellite

```{r}
dataset_csv_path = "../Inputs/fires/sat_ref/csv/"
dataset_parquet_path = "../Inputs/fires/sat_ref/parquet"

# Import csv
fires_ref_sat = open_csv_dataset(
  dataset_csv_path,
  col_types = schema(
    id_bdq = string()
  ) 
)

# Create Year and Month Columns
fires_ref_sat <- fires_ref_sat |> 
  mutate(
    year = year(data_pas),
    month = month(data_pas)
  )

# Export as Parquet
write_dataset(
  fires_ref_sat,
  path = dataset_parquet_path,
  format = "parquet",
  partitioning = c("year")
)
```

## Sisam Data

```{r}
dataset_csv_path = "../Inputs/sisam/csv/"
dataset_parquet_path = "../Inputs/sisam/parquet"

# Import csv
sisam = open_csv_dataset(
  dataset_csv_path,
  col_types = schema(
    longitude = double(),
    latitude = double(),
    co_ppb = double(),
    no2_ppb = double(),
    o3_ppb = double(),
    pm25_ugm3 = double(),
    so2_ugm3 = double(),
    precipitacao_mmdia = double(),
    temperatura_c = double(),
    umidade_relativa_percentual = double(),
    vento_direcao_grau = double(),
    vento_velocidade_ms = double()
    )
)

# Create Year and Month Columns
sisam <- sisam |> 
  mutate(
    year = year(datahora),
    month = month(datahora),
    day = day(datahora)
  )

# Export as Parquet
write_dataset(
  sisam,
  path = dataset_parquet_path,
  format = "parquet",
  partitioning = c("year")
)
```

## Municipality Seats

```{r}
bulk_read_rds(
  muni_seat
)
```


# Reopen from Parquet

Finally, we reopen data with parquet files in the backend.

## All Satellites

```{r}
# Reopen dataset from parquet file 
dataset_parquet_path = "../Inputs/fires/todos_sats/parquet"
fires_all_sats <- open_dataset(
  dataset_parquet_path,
  format = "parquet"
)
```

## Reference Satellite

```{r}
# Reopen dataset from parquet file
dataset_parquet_path = "../Inputs/fires/sat_ref/parquet"
fires_ref_sat <- open_dataset(
  dataset_parquet_path,
  format = "parquet"
)
```

## Sisam Data

```{r}
# Reopen dataset from parquet file
dataset_parquet_path = "../Inputs/sisam/parquet"
sisam <- open_dataset(
  dataset_parquet_path,
  format = "parquet"
)
```

# Create samples for tests 

```{r}
fires_ref_sat_sample <- fires_ref_sat |> 
  filter(year == 2016) |> 
  slice_sample(n = 100) |> 
  collect()

fires_all_sats_sample <- fires_all_sats |> 
  filter(year == 2016) |> 
  slice_sample(n = 100) |> 
  collect()

sisam_sample <- sisam |> 
  filter(year == 2016) |> 
  slice_sample(n = 100) |> 
  collect()

```

# Intersect with municipalities

## Create Spacial DuckDB connection

```{r}
## create connection
conn <- dbConnect(duckdb())
## install and load spatial extension
ddbs_install(conn)
ddbs_load(conn)
```

## Connect Tables to DuckDB

Connect Municipality Points and fires data.

```{r}
ddbs_write_vector(conn, muni_seat, "muni_seat", overwrite = T)
to_duckdb(fires_ref_sat, con = conn, table_name = "fires_ref_sat")
```

## Perform spacial join

```{r}

```



